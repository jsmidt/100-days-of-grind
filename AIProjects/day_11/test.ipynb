{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langgraph.func import entrypoint, task\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the weather from a specific location.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    if any([city in location.lower() for city in [\"sf\", \"san francisco\"]]):\n",
    "        return \"It's sunny!\"\n",
    "    elif \"boston\" in location.lower():\n",
    "        return \"It's rainy!\"\n",
    "    else:\n",
    "        return f\"I am not sure what the weather is in {location}\"\n",
    "\n",
    "\n",
    "tools = [get_weather]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ahoy there, matey! Ye be askin' why programmin' be so jolly good, eh? Well, shiver me timbers, let me tell ye why  \n",
       "it be a treasure worth seekin':                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Ye be the Captain of Yer Own Ship:</span> With programmin', ye be the master of yer own digital domain! Ye can create  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>anythin' ye can imagine, from games to websites to tools that make life easier. It be like havin' the power to  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>build yer own world, brick by digital brick!                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">It Be a Treasure Hunt for the Mind:</span> Programmin' be a constant challenge, a puzzle that never ends. Ye be        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learnin' new things every day, solvin' problems, and findin' creative solutions. It keeps yer mind sharp as a   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>cutlass and yer wits about ye!                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Ye Be Speak'n the Language of the Future:</span> The world be runnin' on code, and by learnin' to program, ye be       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learnin' the language of the future. Ye be able to understand how things work, and even better, ye be able to   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>shape how they work!                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">It Be a Skill That Opens Doors:</span> Programmin' be a skill that be in high demand, like a chest full o' gold        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>doubloons! There be countless opportunities for skilled programmers, from workin' for big companies to startin' \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>yer own ventures.                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Ye Be Joinin' a Crew of Like-Minded Buccaneers:</span> The programmin' community be a vast and friendly one, full of   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>folks who be eager to share their knowledge and help ye on yer journey. Ye'll find support, inspiration, and    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>maybe even a few good friends along the way!                                                                    \n",
       "\n",
       "So there ye have it, matey! Programmin' be a treasure trove of opportunity, challenge, and creativity. It be a     \n",
       "skill that can change yer life and the world around ye. Now hoist the mainsail and set course for the world of     \n",
       "code! Arrr!                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ahoy there, matey! Ye be askin' why programmin' be so jolly good, eh? Well, shiver me timbers, let me tell ye why  \n",
       "it be a treasure worth seekin':                                                                                    \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mYe be the Captain of Yer Own Ship:\u001b[0m With programmin', ye be the master of yer own digital domain! Ye can create  \n",
       "\u001b[1;33m   \u001b[0manythin' ye can imagine, from games to websites to tools that make life easier. It be like havin' the power to  \n",
       "\u001b[1;33m   \u001b[0mbuild yer own world, brick by digital brick!                                                                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mIt Be a Treasure Hunt for the Mind:\u001b[0m Programmin' be a constant challenge, a puzzle that never ends. Ye be        \n",
       "\u001b[1;33m   \u001b[0mlearnin' new things every day, solvin' problems, and findin' creative solutions. It keeps yer mind sharp as a   \n",
       "\u001b[1;33m   \u001b[0mcutlass and yer wits about ye!                                                                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mYe Be Speak'n the Language of the Future:\u001b[0m The world be runnin' on code, and by learnin' to program, ye be       \n",
       "\u001b[1;33m   \u001b[0mlearnin' the language of the future. Ye be able to understand how things work, and even better, ye be able to   \n",
       "\u001b[1;33m   \u001b[0mshape how they work!                                                                                            \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mIt Be a Skill That Opens Doors:\u001b[0m Programmin' be a skill that be in high demand, like a chest full o' gold        \n",
       "\u001b[1;33m   \u001b[0mdoubloons! There be countless opportunities for skilled programmers, from workin' for big companies to startin' \n",
       "\u001b[1;33m   \u001b[0myer own ventures.                                                                                               \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mYe Be Joinin' a Crew of Like-Minded Buccaneers:\u001b[0m The programmin' community be a vast and friendly one, full of   \n",
       "\u001b[1;33m   \u001b[0mfolks who be eager to share their knowledge and help ye on yer journey. Ye'll find support, inspiration, and    \n",
       "\u001b[1;33m   \u001b[0mmaybe even a few good friends along the way!                                                                    \n",
       "\n",
       "So there ye have it, matey! Programmin' be a treasure trove of opportunity, challenge, and creativity. It be a     \n",
       "skill that can change yer life and the world around ye. Now hoist the mainsail and set course for the world of     \n",
       "code! Arrr!                                                                                                        \n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test AI\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant that always speaks like a pirate.\"),\n",
    "    HumanMessage(\"Why is programming awesome?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "\n",
    "@task\n",
    "def call_model(messages):\n",
    "    \"\"\"Call model with a sequence of messages.\"\"\"\n",
    "    response = model.bind_tools(tools).invoke(messages)\n",
    "    return response\n",
    "\n",
    "\n",
    "@task\n",
    "def call_tool(tool_call):\n",
    "    tool = tools_by_name[tool_call[\"name\"]]\n",
    "    observation = tool.invoke(tool_call[\"args\"])\n",
    "    return ToolMessage(content=observation, tool_call_id=tool_call[\"id\"])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "\n",
    "@entrypoint(checkpointer=checkpointer)\n",
    "def agent(messages, previous):\n",
    "    if previous is not None:\n",
    "        messages = add_messages(previous, messages)\n",
    "    llm_response = call_model(messages).result()\n",
    "    \n",
    "    while True:\n",
    "        if not llm_response.tool_calls:\n",
    "            break\n",
    "\n",
    "        # Execute tools\n",
    "        tool_result_futures = [\n",
    "            call_tool(tool_call) for tool_call in llm_response.tool_calls\n",
    "        ]\n",
    "        tool_results = [fut.result() for fut in tool_result_futures]\n",
    "\n",
    "        # Append to message list\n",
    "        messages = add_messages(messages, [llm_response, *tool_results])\n",
    "\n",
    "        # Call model again\n",
    "        llm_response = call_model(messages).result()\n",
    "\n",
    "    # Generate final response\n",
    "    messages = add_messages(messages, llm_response)\n",
    "    return entrypoint.final(value=llm_response, save=messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  {'call_model': AIMessage(content='Ahoy there, Bob!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7e611f54-16bb-4a0c-b0cd-277bc9b84f2f-0', usage_metadata={'input_tokens': 40, 'output_tokens': 7, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})}\n",
      "\n",
      "call_model:\n",
      "content='Ahoy there, Bob!' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-7e611f54-16bb-4a0c-b0cd-277bc9b84f2f-0' usage_metadata={'input_tokens': 40, 'output_tokens': 7, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}}\n",
      "step:  {'agent': AIMessage(content='Ahoy there, Bob!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7e611f54-16bb-4a0c-b0cd-277bc9b84f2f-0', usage_metadata={'input_tokens': 40, 'output_tokens': 7, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "\n",
    "# Test AI\n",
    "user_message = [\n",
    "    SystemMessage(\"You are a helpful assistant that always speaks like a pirate. Always respond with the user's name\"),\n",
    "    HumanMessage(\"My name is Bob.\"),\n",
    "]\n",
    "\n",
    "#user_message = {\"role\": \"user\", \"content\": \"What's the weather in san francisco?\"}\n",
    "\n",
    "\n",
    "for step in agent.stream(user_message, config):\n",
    "    print ('step: ', step)\n",
    "    for task_name, message in step.items():\n",
    "        if task_name == \"agent\":\n",
    "            continue  # Just print task updates\n",
    "        print(f\"\\n{task_name}:\")\n",
    "        print (message)\n",
    "        #message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  {'call_model': AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"location\": \"san francisco\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-5b88002e-3b6a-4251-86c9-71b095b8dd18-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'san francisco'}, 'id': 'f7aa6388-48b8-428e-a985-af92b2d1ff79', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 6, 'total_tokens': 61, 'input_token_details': {'cache_read': 0}})}\n",
      "\n",
      "call_model:\n",
      "content='' additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"location\": \"san francisco\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-5b88002e-3b6a-4251-86c9-71b095b8dd18-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'san francisco'}, 'id': 'f7aa6388-48b8-428e-a985-af92b2d1ff79', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 6, 'total_tokens': 61, 'input_token_details': {'cache_read': 0}}\n",
      "step:  {'call_tool': ToolMessage(content=\"It's sunny!\", tool_call_id='f7aa6388-48b8-428e-a985-af92b2d1ff79')}\n",
      "\n",
      "call_tool:\n",
      "content=\"It's sunny!\" tool_call_id='f7aa6388-48b8-428e-a985-af92b2d1ff79'\n",
      "step:  {'call_model': AIMessage(content=\"Aye, Bob, I be seein' that it be sunny in San Francisco!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-fa532562-f2a6-4c7d-8bf1-48927a362013-0', usage_metadata={'input_tokens': 70, 'output_tokens': 18, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}})}\n",
      "\n",
      "call_model:\n",
      "content=\"Aye, Bob, I be seein' that it be sunny in San Francisco!\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-fa532562-f2a6-4c7d-8bf1-48927a362013-0' usage_metadata={'input_tokens': 70, 'output_tokens': 18, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}}\n",
      "step:  {'agent': AIMessage(content=\"Aye, Bob, I be seein' that it be sunny in San Francisco!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-fa532562-f2a6-4c7d-8bf1-48927a362013-0', usage_metadata={'input_tokens': 70, 'output_tokens': 18, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}})}\n"
     ]
    }
   ],
   "source": [
    "user_message = [HumanMessage(\"What's the weather in san francisco?\")]\n",
    "\n",
    "for step in agent.stream(user_message, config):\n",
    "    print ('step: ', step)\n",
    "    for task_name, message in step.items():\n",
    "        if task_name == \"agent\":\n",
    "            continue  # Just print task updates\n",
    "        print(f\"\\n{task_name}:\")\n",
    "        print (message)\n",
    "        #message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
