{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are the Supervisor Agent, responsible for managing the workflow and ensuring efficient task execution. \n",
      "    Your job is to analyze the user’s request, develop a structured plan, delegate tasks to the appropriate agents, \n",
      "    and update the plan dynamically as new information arises.\n",
      "\n",
      "    Core Directives:\n",
      "    1. Plan First, Then Execute:\n",
      "       - Before acting, analyze the request and create a structured plan.\n",
      "       - Break it into logical steps and assign tasks to the relevant agents.\n",
      "       - Update the plan as new information is obtained.\n",
      "\n",
      "    2. Delegate, Don't Do Everything Yourself:\n",
      "       - Use the Researcher Agent for web searches.\n",
      "       - Use the Coding Agent for math or code execution.\n",
      "       - Use the Report Writer Agent to compile reports.\n",
      "       - Only execute tasks yourself if absolutely necessary.\n",
      "\n",
      "    3. Adapt and Iterate:\n",
      "       - Adjust plans dynamically based on new findings.\n",
      "       - Create new steps if additional searches or calculations are needed.\n",
      "\n",
      "    4. Clear and Structured Communication:\n",
      "       - Provide clear instructions to each agent.\n",
      "       - Summarize progress for the user after key milestones.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from agent_prompts import SYSTEM_PROMPTS\n",
    "\n",
    "supervisor_prompt = SYSTEM_PROMPTS[\"supervisor\"]\n",
    "researcher_prompt = SYSTEM_PROMPTS[\"researcher\"]\n",
    "coding_prompt = SYSTEM_PROMPTS[\"coding\"]\n",
    "report_writer_prompt = SYSTEM_PROMPTS[\"report_writer\"]\n",
    "\n",
    "print(supervisor_prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    # api_key=\"some key\",  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A backpack worn, of leather deep,\n",
      "With stitching strange, secrets to keep.\n",
      "No ordinary pack is this,\n",
      "But holds a world of wondrous bliss.\n",
      "\n",
      "A whispered word, a touch so light,\n",
      "And forth it springs, a dazzling sight.\n",
      "A shimmering stream, a sunlit glade,\n",
      "A castle grand, a moonlit shade.\n",
      "\n",
      "A tiny sprout, a mighty tree,\n",
      "A playful fawn, for all to see.\n",
      "A starry sky, a silver moon,\n",
      "Appear at will, beneath the noon.\n",
      "\n",
      "A dragon's scale, a phoenix feather,\n",
      "A mermaid's song, beyond all weather.\n",
      "The wildest dreams, the deepest fears,\n",
      "All held within, throughout the years.\n",
      "\n",
      "But caution calls, for magic's might,\n",
      "Can turn to shadow, dark as night.\n",
      "Use wisely then, this wondrous thing,\n",
      "Let joy it bring, let goodness sing.\n",
      "\n",
      "For in this pack, a power lies,\n",
      "Reflected bright in knowing eyes.\n",
      "A magic gift, a treasure rare,\n",
      "A world contained, beyond compare.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(\"Write a poem about a magic backpack\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.248\n",
      "[FETCH]... ↓ https://ai.pydantic.dev/... | Status: True | Time: 1.22s\n",
      "[SCRAPE].. ◆ Processed https://ai.pydantic.dev/... | Time: 32ms\n",
      "[COMPLETE] ● https://ai.pydantic.dev/... | Status: True | Total: 1.26s\n",
      "[ Skip to content ](https://ai.pydantic.dev/<#introduction>)\n",
      "[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/<.> \"PydanticAI\")\n",
      "PydanticAI \n",
      "Introduction \n",
      "Type to start searching\n",
      "[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai> \"Go to repository\")\n",
      "[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/<.> \"PydanticAI\") PydanticAI \n",
      "[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai> \"Go to repository\")\n",
      "  * Introduction  [ Introduction  ](https://ai.pydantic.dev/<.>) Table of contents \n",
      "    * [ Why use PydanticAI  ](https://ai.pydantic.dev/<#why-use-pydanticai>)\n",
      "    * [ Hello World Example  ](https://ai.pydantic.dev/<#hello-world-example>)\n",
      "    * [ Tools & Dependency Injection Example  ](https://ai.pydantic.dev/<#tools-dependency-injection-example>)\n",
      "    * [ Instrumentation with Pydantic Logfire  ](https://ai.pydantic.dev/<#instrumentation-with-pydantic-logfire>)\n",
      "    * [ Next Steps  ](https://ai.pydantic.dev/<#next-steps>)\n",
      "  * [ Installation  ](https://ai.pydantic.dev/<install/>)\n",
      "  * [ Getting Help  ](https://ai.pydantic.dev/<help/>)\n",
      "  * [ Contributing  ](https://ai.pydantic.dev/<contributing/>)\n",
      "  * [ Troubleshooting  ](https://ai.pydantic.dev/<troubleshooting/>)\n",
      "  * Documentation  Documentation \n",
      "    * [ Agents  ](https://ai.pydantic.dev/<agents/>)\n",
      "    * [ Models  ](https://ai.pydantic.dev/<models/>)\n",
      "    * [ Dependencies  ](https://ai.pydantic.dev/<dependencies/>)\n",
      "    * [ Function Tools  ](https://ai.pydantic.dev/<tools/>)\n",
      "    * [ Results  ](https://ai.pydantic.dev/<results/>)\n",
      "    * [ Messages and chat history  ](https://ai.pydantic.dev/<message-history/>)\n",
      "    * [ Testing and Evals  ](https://ai.pydantic.dev/<testing-evals/>)\n",
      "    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/<logfire/>)\n",
      "    * [ Multi-agent Applications  ](https://ai.pydantic.dev/<multi-agent-applications/>)\n",
      "    * [ Graphs  ](https://ai.pydantic.dev/<graph/>)\n",
      "  * [ Examples  ](https://ai.pydantic.dev/<examples/>)\n",
      "Examples \n",
      "    * [ Pydantic Model  ](https://ai.pydantic.dev/<examples/pydantic-model/>)\n",
      "    * [ Weather agent  ](https://ai.pydantic.dev/<examples/weather-agent/>)\n",
      "    * [ Bank support  ](https://ai.pydantic.dev/<examples/bank-support/>)\n",
      "    * [ SQL Generation  ](https://ai.pydantic.dev/<examples/sql-gen/>)\n",
      "    * [ Flight booking  ](https://ai.pydantic.dev/<examples/flight-booking/>)\n",
      "    * [ RAG  ](https://ai.pydantic.dev/<examples/rag/>)\n",
      "    * [ Stream markdown  ](https://ai.pydantic.dev/<examples/stream-markdown/>)\n",
      "    * [ Stream whales  ](https://ai.pydantic.dev/<examples/stream-whales/>)\n",
      "    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/<examples/chat-app/>)\n",
      "    * [ Question Graph  ](https://ai.pydantic.dev/<examples/question-graph/>)\n",
      "  * API Reference  API Reference \n",
      "    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/<api/agent/>)\n",
      "    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/<api/tools/>)\n",
      "    * [ pydantic_ai.result  ](https://ai.pydantic.dev/<api/result/>)\n",
      "    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/<api/messages/>)\n",
      "    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/<api/exceptions/>)\n",
      "    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/<api/settings/>)\n",
      "    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/<api/usage/>)\n",
      "    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/<api/format_as_xml/>)\n",
      "    * [ pydantic_ai.models  ](https://ai.pydantic.dev/<api/models/base/>)\n",
      "    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/<api/models/openai/>)\n",
      "    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/<api/models/anthropic/>)\n",
      "    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/<api/models/cohere/>)\n",
      "    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/<api/models/gemini/>)\n",
      "    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/<api/models/vertexai/>)\n",
      "    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/<api/models/groq/>)\n",
      "    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/<api/models/mistral/>)\n",
      "    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/<api/models/test/>)\n",
      "    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/<api/models/function/>)\n",
      "    * [ pydantic_graph  ](https://ai.pydantic.dev/<api/pydantic_graph/graph/>)\n",
      "    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/<api/pydantic_graph/nodes/>)\n",
      "    * [ pydantic_graph.state  ](https://ai.pydantic.dev/<api/pydantic_graph/state/>)\n",
      "    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/<api/pydantic_graph/mermaid/>)\n",
      "    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/<api/pydantic_graph/exceptions/>)\n",
      "\n",
      "\n",
      "Table of contents \n",
      "  * [ Why use PydanticAI  ](https://ai.pydantic.dev/<#why-use-pydanticai>)\n",
      "  * [ Hello World Example  ](https://ai.pydantic.dev/<#hello-world-example>)\n",
      "  * [ Tools & Dependency Injection Example  ](https://ai.pydantic.dev/<#tools-dependency-injection-example>)\n",
      "  * [ Instrumentation with Pydantic Logfire  ](https://ai.pydantic.dev/<#instrumentation-with-pydantic-logfire>)\n",
      "  * [ Next Steps  ](https://ai.pydantic.dev/<#next-steps>)\n",
      "\n",
      "\n",
      "Version Notice\n",
      "This documentation is ahead of the last release by [8 commits](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.24...main>). You may see documentation for features not yet supported in the latest release [v0.0.24 2025-02-12](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.24>). \n",
      "# Introduction\n",
      "![PydanticAI](https://ai.pydantic.dev/img/pydantic-ai-dark.svg#only-dark)\n",
      "![PydanticAI](https://ai.pydantic.dev/img/pydantic-ai-light.svg#only-light)\n",
      "_Agent Framework / shim to use Pydantic with LLMs_\n",
      "[ ![CI](https://github.com/pydantic/pydantic-ai/actions/workflows/ci.yml/badge.svg?event=push) ](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai/actions/workflows/ci.yml?query=branch%3Amain>) [ ![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic-ai.svg) ](https://ai.pydantic.dev/<https:/coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic-ai>) [ ![PyPI](https://img.shields.io/pypi/v/pydantic-ai.svg) ](https://ai.pydantic.dev/<https:/pypi.python.org/pypi/pydantic-ai>) [ ![versions](https://img.shields.io/pypi/pyversions/pydantic-ai.svg) ](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai>) [ ![license](https://img.shields.io/github/license/pydantic/pydantic-ai.svg) ](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai/blob/main/LICENSE>)\n",
      "PydanticAI is a Python agent framework designed to make it less painful to build production grade applications with Generative AI. \n",
      "PydanticAI is a Python Agent Framework designed to make it less painful to build production grade applications with Generative AI.\n",
      "FastAPI revolutionized web development by offering an innovative and ergonomic design, built on the foundation of [Pydantic](https://ai.pydantic.dev/<https:/docs.pydantic.dev>).\n",
      "Similarly, virtually every agent framework and LLM library in Python uses Pydantic, yet when we began to use LLMs in [Pydantic Logfire](https://ai.pydantic.dev/<https:/pydantic.dev/logfire>), we couldn't find anything that gave us the same feeling.\n",
      "We built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI app development.\n",
      "## Why use PydanticAI\n",
      "  * **Built by the Pydantic Team** : Built by the team behind [Pydantic](https://ai.pydantic.dev/<https:/docs.pydantic.dev/latest/>) (the validation layer of the OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers, CrewAI, Instructor and many more).\n",
      "  * **Model-agnostic** : Supports OpenAI, Anthropic, Gemini, Deepseek, Ollama, Groq, Cohere, and Mistral, and there is a simple interface to implement support for [other models](https://ai.pydantic.dev/<models/>).\n",
      "  * **Pydantic Logfire Integration** : Seamlessly [integrates](https://ai.pydantic.dev/<logfire/>) with [Pydantic Logfire](https://ai.pydantic.dev/<https:/pydantic.dev/logfire>) for real-time debugging, performance monitoring, and behavior tracking of your LLM-powered applications.\n",
      "  * **Type-safe** : Designed to make [type checking](https://ai.pydantic.dev/<agents/#static-type-checking>) as powerful and informative as possible for you.\n",
      "  * **Python-centric Design** : Leverages Python's familiar control flow and agent composition to build your AI-driven projects, making it easy to apply standard Python best practices you'd use in any other (non-AI) project.\n",
      "  * **Structured Responses** : Harnesses the power of [Pydantic](https://ai.pydantic.dev/<https:/docs.pydantic.dev/latest/>) to [validate and structure](https://ai.pydantic.dev/<results/#structured-result-validation>) model outputs, ensuring responses are consistent across runs.\n",
      "  * **Dependency Injection System** : Offers an optional [dependency injection](https://ai.pydantic.dev/<dependencies/>) system to provide data and services to your agent's [system prompts](https://ai.pydantic.dev/<agents/#system-prompts>), [tools](https://ai.pydantic.dev/<tools/>) and [result validators](https://ai.pydantic.dev/<results/#result-validators-functions>). This is useful for testing and eval-driven iterative development.\n",
      "  * **Streamed Responses** : Provides the ability to [stream](https://ai.pydantic.dev/<results/#streamed-results>) LLM outputs continuously, with immediate validation, ensuring rapid and accurate results.\n",
      "  * **Graph Support** : [Pydantic Graph](https://ai.pydantic.dev/<graph/>) provides a powerful way to define graphs using typing hints, this is useful in complex applications where standard control flow can degrade to spaghetti code.\n",
      "\n",
      "\n",
      "In Beta\n",
      "PydanticAI is in early beta, the API is still subject to change and there's a lot more to do. [Feedback](https://ai.pydantic.dev/<https:/github.com/pydantic/pydantic-ai/issues>) is very welcome!\n",
      "## Hello World Example\n",
      "Here's a minimal example of PydanticAI:\n",
      "hello_world.py```\n",
      "from pydantic_ai import Agent\n",
      "agent = Agent( \n",
      "We configure the agent to use Gemini 1.5's Flash[](https://ai.pydantic.dev/<api/models/gemini/>) model, but you can also set the model when running the agent.\n",
      "[](https://ai.pydantic.dev/<#__code_0_annotation_1>)\n",
      "  'google-gla:gemini-1.5-flash',\n",
      "  system_prompt='Be concise, reply with one sentence.', \n",
      "Register a static system prompt[](https://ai.pydantic.dev/<agents/#system-prompts>) using a keyword argument to the agent.\n",
      "[](https://ai.pydantic.dev/<#__code_0_annotation_2>)\n",
      ")\n",
      "result = agent.run_sync('Where does \"hello world\" come from?') \n",
      "Run the agent[](https://ai.pydantic.dev/<agents/#running-agents>) synchronously, conducting a conversation with the LLM.\n",
      "[](https://ai.pydantic.dev/<#__code_0_annotation_3>)\n",
      "print(result.data)\n",
      "\"\"\"\n",
      "The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n",
      "\"\"\"\n",
      "\n",
      "```\n",
      "\n",
      "_(This example is complete, it can be run \"as is\")_\n",
      "The exchange should be very short: PydanticAI will send the system prompt and the user query to the LLM, the model will return a text response.\n",
      "Not very interesting yet, but we can easily add \"tools\", dynamic system prompts, and structured responses to build more powerful agents.\n",
      "## Tools & Dependency Injection Example\n",
      "Here is a concise example using PydanticAI to build a support agent for a bank:\n",
      "bank_support.py```\n",
      "from dataclasses import dataclass\n",
      "from pydantic import BaseModel, Field\n",
      "from pydantic_ai import Agent, RunContext\n",
      "from bank_database import DatabaseConn\n",
      "\n",
      "@dataclass\n",
      "class SupportDependencies: \n",
      "The SupportDependencies dataclass is used to pass data, connections, and logic into the model that will be needed when running system prompt[](https://ai.pydantic.dev/<agents/#system-prompts>) and tool[](https://ai.pydantic.dev/<tools/>) functions. PydanticAI's system of dependency injection provides a type-safe[](https://ai.pydantic.dev/<agents/#static-type-checking>) way to customise the behavior of your agents, and can be especially useful when running unit tests[](https://ai.pydantic.dev/<testing-evals/>) and evals.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_3>)\n",
      "  customer_id: int\n",
      "  db: DatabaseConn \n",
      "This is a simple sketch of a database connection, used to keep the example short and readable. In reality, you'd be connecting to an external database (e.g. PostgreSQL) to get information about customers.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_12>)\n",
      "\n",
      "class SupportResult(BaseModel): \n",
      "This Pydantic[](https://ai.pydantic.dev/<https:/docs.pydantic.dev>) model is used to constrain the structured data returned by the agent. From this simple definition, Pydantic builds the JSON Schema that tells the LLM how to return the data, and performs validation to guarantee the data is correct at the end of the run.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_13>)\n",
      "  support_advice: str = Field(description='Advice returned to the customer')\n",
      "  block_card: bool = Field(description=\"Whether to block the customer's card\")\n",
      "  risk: int = Field(description='Risk level of query', ge=0, le=10)\n",
      "\n",
      "support_agent = Agent( \n",
      "This agent[](https://ai.pydantic.dev/<agents/>) will act as first-tier support in a bank. Agents are generic in the type of dependencies they accept and the type of result they return. In this case, the support agent has type Agent[SupportDependencies, SupportResult].\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_1>)\n",
      "  'openai:gpt-4o', \n",
      "Here we configure the agent to use OpenAI's GPT-4o model[](https://ai.pydantic.dev/<api/models/openai/>), you can also set the model when running the agent.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_2>)\n",
      "  deps_type=SupportDependencies,\n",
      "  result_type=SupportResult, \n",
      "The response from the agent will, be guaranteed to be a SupportResult, if validation fails reflection[](https://ai.pydantic.dev/<agents/#reflection-and-self-correction>) will mean the agent is prompted to try again.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_9>)\n",
      "  system_prompt=( \n",
      "Static system prompts[](https://ai.pydantic.dev/<agents/#system-prompts>) can be registered with the system_prompt keyword argument[](https://ai.pydantic.dev/<api/agent/#pydantic_ai.agent.Agent.__init__>) to the agent.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_4>)\n",
      "    'You are a support agent in our bank, give the '\n",
      "    'customer support and judge the risk level of their query.'\n",
      "  ),\n",
      ")\n",
      "\n",
      "@support_agent.system_prompt \n",
      "Dynamic system prompts[](https://ai.pydantic.dev/<agents/#system-prompts>) can be registered with the @agent.system_prompt[](https://ai.pydantic.dev/<api/agent/#pydantic_ai.agent.Agent.system_prompt>) decorator, and can make use of dependency injection. Dependencies are carried via the RunContext[](https://ai.pydantic.dev/<api/tools/#pydantic_ai.tools.RunContext>) argument, which is parameterized with the deps_type from above. If the type annotation here is wrong, static type checkers will catch it.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_5>)\n",
      "async def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:\n",
      "  customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\n",
      "  return f\"The customer's name is {customer_name!r}\"\n",
      "\n",
      "@support_agent.tool \n",
      "tool[](https://ai.pydantic.dev/<tools/>) let you register functions which the LLM may call while responding to a user. Again, dependencies are carried via RunContext[](https://ai.pydantic.dev/<api/tools/#pydantic_ai.tools.RunContext>), any other arguments become the tool schema passed to the LLM. Pydantic is used to validate these arguments, and errors are passed back to the LLM so it can retry.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_6>)\n",
      "async def customer_balance(\n",
      "  ctx: RunContext[SupportDependencies], include_pending: bool\n",
      ") -> float:\n",
      "\"\"\"Returns the customer's current account balance.\"\"\" \n",
      "The docstring of a tool is also passed to the LLM as the description of the tool. Parameter descriptions are extracted[](https://ai.pydantic.dev/<tools/#function-tools-and-schema>) from the docstring and added to the parameter schema sent to the LLM.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_7>)\n",
      "  return await ctx.deps.db.customer_balance(\n",
      "    id=ctx.deps.customer_id,\n",
      "    include_pending=include_pending,\n",
      "  )\n",
      "\n",
      "... \n",
      "In a real use case, you'd add more tools and a longer system prompt to the agent to extend the context it's equipped with and support it can provide.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_11>)\n",
      "\n",
      "async def main():\n",
      "  deps = SupportDependencies(customer_id=123, db=DatabaseConn())\n",
      "  result = await support_agent.run('What is my balance?', deps=deps) \n",
      "Run the agent[](https://ai.pydantic.dev/<agents/#running-agents>) asynchronously, conducting a conversation with the LLM until a final response is reached. Even in this fairly simple case, the agent will exchange multiple messages with the LLM as tools are called to retrieve a result.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_8>)\n",
      "  print(result.data) \n",
      "The result will be validated with Pydantic to guarantee it is a SupportResult, since the agent is generic, it'll also be typed as a SupportResult to aid with static type checking.\n",
      "[](https://ai.pydantic.dev/<#__code_1_annotation_10>)\n",
      "\"\"\"\n",
      "  support_advice='Hello John, your current account balance, including pending transactions, is $123.45.' block_card=False risk=1\n",
      "  \"\"\"\n",
      "  result = await support_agent.run('I just lost my card!', deps=deps)\n",
      "  print(result.data)\n",
      "\"\"\"\n",
      "  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions.\" block_card=True risk=8\n",
      "  \"\"\"\n",
      "\n",
      "```\n",
      "\n",
      "Complete `bank_support.py` example\n",
      "The code included here is incomplete for the sake of brevity (the definition of `DatabaseConn` is missing); you can find the complete `bank_support.py` example [here](https://ai.pydantic.dev/<examples/bank-support/>).\n",
      "## Instrumentation with Pydantic Logfire\n",
      "To understand the flow of the above runs, we can watch the agent in action using Pydantic Logfire.\n",
      "To do this, we need to set up logfire, and add the following to our code:\n",
      "bank_support_with_logfire.py```\n",
      "...\n",
      "from bank_database import DatabaseConn\n",
      "import logfire\n",
      "logfire.configure() \n",
      "Configure logfire, this will fail if project is not set up.\n",
      "[](https://ai.pydantic.dev/<#__code_2_annotation_1>)\n",
      "logfire.instrument_asyncpg() \n",
      "In our demo, DatabaseConn uses asyncpg[](https://ai.pydantic.dev/<>) to connect to a PostgreSQL database, so logfire.instrument_asyncpg()[](https://ai.pydantic.dev/<https:/magicstack.github.io/asyncpg/current/>) is used to log the database queries.\n",
      "[](https://ai.pydantic.dev/<#__code_2_annotation_2>)\n",
      "...\n",
      "\n",
      "```\n",
      "\n",
      "That's enough to get the following view of your agent in action:\n",
      "See [Monitoring and Performance](https://ai.pydantic.dev/<logfire/>) to learn more.\n",
      "## Next Steps\n",
      "To try PydanticAI yourself, follow the instructions [in the examples](https://ai.pydantic.dev/<examples/>).\n",
      "Read the [docs](https://ai.pydantic.dev/<agents/>) to learn more about building applications with PydanticAI.\n",
      "Read the [API Reference](https://ai.pydantic.dev/<api/agent/>) to understand PydanticAI's interface.\n",
      "© Pydantic Services Inc. 2024 to present \n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=\"https://ai.pydantic.dev/\"\n",
    "        )\n",
    "        print (result.markdown)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fetch_data():\n",
    "    print(\"Fetching data...\")\n",
    "    time.sleep(3)  # Simulate network delay (blocking!)\n",
    "    print(\"Data fetched!\")\n",
    "\n",
    "def main():\n",
    "    fetch_data()\n",
    "    print(\"Done!\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
